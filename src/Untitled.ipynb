{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "545c2547-dc20-45f1-8970-c35b7232dbef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                      Version\n",
      "---------------------------- -----------\n",
      "absl-py                      2.1.0\n",
      "astunparse                   1.6.3\n",
      "certifi                      2024.8.30\n",
      "charset-normalizer           3.3.2\n",
      "efficientnet                 1.0.0\n",
      "flatbuffers                  24.3.25\n",
      "gast                         0.6.0\n",
      "google-pasta                 0.2.0\n",
      "grpcio                       1.66.1\n",
      "h5py                         3.11.0\n",
      "idna                         3.10\n",
      "image-classifiers            1.0.0\n",
      "imageio                      2.35.1\n",
      "keras                        3.5.0\n",
      "Keras-Applications           1.0.7\n",
      "lazy_loader                  0.4\n",
      "libclang                     18.1.1\n",
      "Markdown                     3.7\n",
      "markdown-it-py               3.0.0\n",
      "MarkupSafe                   2.1.5\n",
      "mdurl                        0.1.2\n",
      "ml-dtypes                    0.4.1\n",
      "namex                        0.0.8\n",
      "networkx                     3.3\n",
      "numpy                        1.26.4\n",
      "opt-einsum                   3.3.0\n",
      "optree                       0.12.1\n",
      "packaging                    24.1\n",
      "pandas                       2.2.3\n",
      "pillow                       10.4.0\n",
      "pip                          24.2\n",
      "protobuf                     4.25.5\n",
      "pydot                        2.0.0\n",
      "Pygments                     2.18.0\n",
      "pyparsing                    3.1.4\n",
      "python-dateutil              2.9.0.post0\n",
      "pytz                         2024.2\n",
      "requests                     2.32.3\n",
      "rich                         13.8.1\n",
      "scikit-image                 0.24.0\n",
      "scipy                        1.14.1\n",
      "segmentation-models          1.0.1\n",
      "setuptools                   69.5.1\n",
      "six                          1.16.0\n",
      "tabulate                     0.9.0\n",
      "tensorboard                  2.17.1\n",
      "tensorboard-data-server      0.7.2\n",
      "tensorflow                   2.17.0\n",
      "tensorflow-io-gcs-filesystem 0.37.1\n",
      "termcolor                    2.4.0\n",
      "tifffile                     2024.9.20\n",
      "tqdm                         4.66.4\n",
      "typing_extensions            4.12.2\n",
      "tzdata                       2024.1\n",
      "urllib3                      2.2.3\n",
      "Werkzeug                     3.0.4\n",
      "wheel                        0.43.0\n",
      "wrapt                        1.16.0\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d1eacf3-a87a-42e9-81f7-08f7cfa69d9f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Keras requires TensorFlow 2.2 or higher. Install TensorFlow via `pip install tensorflow`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/__init__.py:3\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomRotation\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/__init__.py:5\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomRotation\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKeras requires TensorFlow 2.2 or higher. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInstall TensorFlow via `pip install tensorflow`\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m activations\n",
      "\u001b[0;31mImportError\u001b[0m: Keras requires TensorFlow 2.2 or higher. Install TensorFlow via `pip install tensorflow`"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "import segmentation_models as sm\n",
    "\n",
    "\n",
    "# Define paths for DRIVE dataset based on your directory structure\n",
    "DATA_DIR = '../data/raw/'\n",
    "\n",
    "# Training and testing directories\n",
    "x_train_dir = os.path.join(DATA_DIR, 'training/input')\n",
    "y_train_dir = os.path.join(DATA_DIR, 'training/target')\n",
    "\n",
    "x_test_dir = os.path.join(DATA_DIR, 'test/input')\n",
    "y_test_dir = os.path.join(DATA_DIR, 'test/target')\n",
    "\n",
    "# Define the single class for binary segmentation\n",
    "CLASSES = ['vessel']\n",
    "\n",
    "# Function to visualize images and masks\n",
    "def visualize(**images):\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(16, 5))\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        plt.imshow(image, cmap='gray' if image.ndim == 2 else None)\n",
    "    plt.show()\n",
    "\n",
    "# Function to normalize images for visualization\n",
    "def denormalize(x):\n",
    "    x_max = np.percentile(x, 98)\n",
    "    x_min = np.percentile(x, 2)    \n",
    "    x = (x - x_min) / (x_max - x_min)\n",
    "    x = x.clip(0, 1)\n",
    "    return x\n",
    "\n",
    "# Dataset class\n",
    "class Dataset:\n",
    "    CLASSES = ['vessel']\n",
    "    \n",
    "    def __init__(self, images_dir, masks_dir, classes=None, augmentation=None, preprocessing=None):\n",
    "        self.ids = os.listdir(images_dir)\n",
    "        self.images_fps = [os.path.join(images_dir, image_id) for image_id in self.ids]\n",
    "        self.masks_fps = [os.path.join(masks_dir, image_id) for image_id in self.ids]\n",
    "        \n",
    "        # Convert str names to class values on masks\n",
    "        self.class_values = [self.CLASSES.index(cls.lower()) for cls in classes]\n",
    "        \n",
    "        self.augmentation = augmentation\n",
    "        self.preprocessing = preprocessing\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        # Read data\n",
    "        image = cv2.imread(self.images_fps[i])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.imread(self.masks_fps[i], 0)\n",
    "        \n",
    "        # Extract certain classes from mask (vessels)\n",
    "        masks = [(mask == v) for v in self.class_values]\n",
    "        mask = np.stack(masks, axis=-1).astype('float')\n",
    "        \n",
    "        # Add background if mask is not binary\n",
    "        if mask.shape[-1] != 1:\n",
    "            background = 1 - mask.sum(axis=-1, keepdims=True)\n",
    "            mask = np.concatenate((mask, background), axis=-1)\n",
    "        \n",
    "        # Apply augmentations\n",
    "        if self.augmentation:\n",
    "            sample = self.augmentation(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "        \n",
    "        # Apply preprocessing\n",
    "        if self.preprocessing:\n",
    "            sample = self.preprocessing(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "            \n",
    "        return image, mask\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "# DataLoader class\n",
    "class Dataloder(keras.utils.Sequence):\n",
    "    def __init__(self, dataset, batch_size=1, shuffle=False):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indexes = np.arange(len(dataset))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        start = i * self.batch_size\n",
    "        stop = (i + 1) * self.batch_size\n",
    "        data = []\n",
    "        for j in range(start, stop):\n",
    "            data.append(self.dataset[j])\n",
    "        batch = [np.stack(samples, axis=0) for samples in zip(*data)]\n",
    "        return batch\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.indexes) // self.batch_size\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            self.indexes = np.random.permutation(self.indexes)\n",
    "\n",
    "# Define augmentations\n",
    "def get_training_augmentation():\n",
    "    train_transform = [\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.ShiftScaleRotate(scale_limit=0.5, rotate_limit=0, shift_limit=0.1, p=1, border_mode=0),\n",
    "        A.PadIfNeeded(min_height=512, min_width=512, always_apply=True, border_mode=0),\n",
    "        A.RandomCrop(height=512, width=512, always_apply=True),\n",
    "        A.IAAAdditiveGaussianNoise(p=0.2),\n",
    "        A.OneOf([\n",
    "            A.CLAHE(p=1),\n",
    "            A.RandomBrightness(p=1),\n",
    "            A.RandomGamma(p=1),\n",
    "        ], p=0.9),\n",
    "        A.OneOf([\n",
    "            A.IAASharpen(p=1),\n",
    "            A.Blur(blur_limit=3, p=1),\n",
    "            A.MotionBlur(blur_limit=3, p=1),\n",
    "        ], p=0.9),\n",
    "        A.OneOf([\n",
    "            A.RandomContrast(p=1),\n",
    "            A.HueSaturationValue(p=1),\n",
    "        ], p=0.9),\n",
    "        A.Lambda(mask=lambda x, **kwargs: x.round().clip(0, 1))\n",
    "    ]\n",
    "    return A.Compose(train_transform)\n",
    "\n",
    "def get_validation_augmentation():\n",
    "    return A.Compose([A.PadIfNeeded(512, 512)])\n",
    "\n",
    "def get_preprocessing(preprocessing_fn):\n",
    "    _transform = [A.Lambda(image=preprocessing_fn)]\n",
    "    return A.Compose(_transform)\n",
    "\n",
    "# Model definition\n",
    "BACKBONE = 'efficientnetb3'\n",
    "BATCH_SIZE = 4\n",
    "LR = 0.0001\n",
    "EPOCHS = 40\n",
    "preprocess_input = sm.get_preprocessing(BACKBONE)\n",
    "\n",
    "n_classes = 1  # Binary segmentation (vessel vs. background)\n",
    "activation = 'sigmoid'\n",
    "\n",
    "model = sm.Unet(BACKBONE, classes=n_classes, activation=activation)\n",
    "optim = keras.optimizers.Adam(LR)\n",
    "dice_loss = sm.losses.DiceLoss()\n",
    "focal_loss = sm.losses.BinaryFocalLoss()\n",
    "total_loss = dice_loss + (1 * focal_loss)\n",
    "metrics = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5)]\n",
    "model.compile(optim, total_loss, metrics)\n",
    "\n",
    "# Dataset preparation\n",
    "train_dataset = Dataset(\n",
    "    x_train_dir, \n",
    "    y_train_dir, \n",
    "    classes=CLASSES, \n",
    "    augmentation=get_training_augmentation(),\n",
    "    preprocessing=get_preprocessing(preprocess_input),\n",
    ")\n",
    "\n",
    "valid_dataset = Dataset(\n",
    "    x_test_dir, \n",
    "    y_test_dir, \n",
    "    classes=CLASSES, \n",
    "    augmentation=get_validation_augmentation(),\n",
    "    preprocessing=get_preprocessing(preprocess_input),\n",
    ")\n",
    "\n",
    "train_dataloader = Dataloder(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_dataloader = Dataloder(valid_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Training\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint('./best_model.h5', save_weights_only=True, save_best_only=True, mode='min'),\n",
    "    keras.callbacks.ReduceLROnPlateau(),\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataloader, \n",
    "    steps_per_epoch=len(train_dataloader), \n",
    "    epochs=EPOCHS, \n",
    "    callbacks=callbacks, \n",
    "    validation_data=valid_dataloader, \n",
    "    validation_steps=len(valid_dataloader),\n",
    ")\n",
    "\n",
    "# Evaluation on test set\n",
    "test_dataset = Dataset(\n",
    "    x_test_dir, \n",
    "    y_test_dir, \n",
    "    classes=CLASSES, \n",
    "    augmentation=get_validation_augmentation(),\n",
    "    preprocessing=get_preprocessing(preprocess_input),\n",
    ")\n",
    "\n",
    "test_dataloader = Dataloder(test_dataset, batch_size=1, shuffle=False)\n",
    "model.load_weights('best_model.h5') \n",
    "scores = model.evaluate(test_dataloader)\n",
    "\n",
    "print(f\"Loss: {scores[0]:.5f}\")\n",
    "for metric, value in zip(metrics, scores[1:]):\n",
    "    print(f\"mean {metric.__name__}: {value:.5f}\")\n",
    "\n",
    "# Visualization of results\n",
    "n = 5\n",
    "ids = np.random.choice(np.arange(len(test_dataset)), size=n)\n",
    "\n",
    "for i in ids:\n",
    "    image, gt_mask = test_dataset[i]\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    pr_mask = model.predict(image).round()\n",
    "    visualize(\n",
    "        image=denormalize(image.squeeze()),\n",
    "        gt_mask=gt_mask.squeeze(),\n",
    "        pr_mask=pr_mask.squeeze(),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df49ab08-387e-4437-987e-99d59eec9c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                      Version\n",
      "---------------------------- -----------\n",
      "absl-py                      2.1.0\n",
      "astunparse                   1.6.3\n",
      "certifi                      2024.8.30\n",
      "charset-normalizer           3.3.2\n",
      "efficientnet                 1.0.0\n",
      "flatbuffers                  24.3.25\n",
      "gast                         0.6.0\n",
      "google-pasta                 0.2.0\n",
      "grpcio                       1.66.1\n",
      "h5py                         3.11.0\n",
      "idna                         3.10\n",
      "image-classifiers            1.0.0\n",
      "imageio                      2.35.1\n",
      "keras                        3.5.0\n",
      "Keras-Applications           1.0.7\n",
      "lazy_loader                  0.4\n",
      "libclang                     18.1.1\n",
      "Markdown                     3.7\n",
      "markdown-it-py               3.0.0\n",
      "MarkupSafe                   2.1.5\n",
      "mdurl                        0.1.2\n",
      "ml-dtypes                    0.4.1\n",
      "namex                        0.0.8\n",
      "networkx                     3.3\n",
      "numpy                        1.26.4\n",
      "opt-einsum                   3.3.0\n",
      "optree                       0.12.1\n",
      "packaging                    24.1\n",
      "pandas                       2.2.3\n",
      "pillow                       10.4.0\n",
      "pip                          24.2\n",
      "protobuf                     4.25.5\n",
      "pydot                        2.0.0\n",
      "Pygments                     2.18.0\n",
      "pyparsing                    3.1.4\n",
      "python-dateutil              2.9.0.post0\n",
      "pytz                         2024.2\n",
      "requests                     2.32.3\n",
      "rich                         13.8.1\n",
      "scikit-image                 0.24.0\n",
      "scipy                        1.14.1\n",
      "segmentation-models          1.0.1\n",
      "setuptools                   69.5.1\n",
      "six                          1.16.0\n",
      "tabulate                     0.9.0\n",
      "tensorboard                  2.17.1\n",
      "tensorboard-data-server      0.7.2\n",
      "tensorflow                   2.17.0\n",
      "tensorflow-io-gcs-filesystem 0.37.1\n",
      "termcolor                    2.4.0\n",
      "tifffile                     2024.9.20\n",
      "tqdm                         4.66.4\n",
      "typing_extensions            4.12.2\n",
      "tzdata                       2024.1\n",
      "urllib3                      2.2.3\n",
      "Werkzeug                     3.0.4\n",
      "wheel                        0.43.0\n",
      "wrapt                        1.16.0\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
